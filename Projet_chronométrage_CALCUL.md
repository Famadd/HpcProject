# ğŸš€ Projet : ChronomÃ©trage des calculs matriciels (CPU & GPU)

## ğŸ¯ Objectif du projet
Le but de ce projet est dâ€™implÃ©menter diffÃ©rents algorithmes de calcul de matrices carrÃ©es afin de **comparer leurs performances** sur CPU et GPU.  
Les opÃ©rations testÃ©es sont :  
- **Addition de matrices**  
- **Produit matriciel**  
- **Produit de Hadamard**  

ğŸ‘‰ Les temps dâ€™exÃ©cution sont mesurÃ©s pour des matrices de taille croissante, afin dâ€™Ã©valuer lâ€™impact de lâ€™optimisation et du matÃ©riel utilisÃ©.  

Ce projet est une **initiation Ã  lâ€™informatique HPC** et Ã  la **programmation parallÃ¨le** via lâ€™API CUDA.  

---

## ğŸ–¥ï¸ Environnement et prÃ©requis
- **Langage :** C++20 et plus  
- **DÃ©pendances :**
  - [CMake](https://cmake.org/download/)
  - [CUDA Toolkit 13.0+](https://developer.nvidia.com/cuda-downloads)  
  - `nvcc` (compilateur CUDA)  
  - **cuBLAS** (inclus dans le CUDA Toolkit)  

## âš¡ ExÃ©cution du programme
  - Placez vous dans le build d'un des deux dossiers TestsCPU/TestsGPU
  - Entrez la commande *cmake..*
  - Vous trouverez l'exÃ©cutable dans le dossier bin/

---

## âš™ï¸ Description des algorithmes

### **CPU**
- **Algorithme 1 :** ImplÃ©mentation naÃ¯ve (non optimisÃ©e).  
- **Algorithme 2 :** ImplÃ©mentation linÃ©aire avec **accÃ¨s mÃ©moire contigu** (optimisÃ© CPU).  

### **GPU**
- **Algorithme 3 :** ImplÃ©mentation linÃ©aire avec **optimisation GPU CUDA**.  

---

## ğŸ“Š RÃ©sultats expÃ©rimentaux

### CPU (Intel i3-12100F, 32 Go RAM)

#### Algorithme 1 (naÃ¯f)
| Taille NÃ—N | Produit matriciel | Addition | Hadamard |
|------------|------------------:|---------:|----------:|
| 1000       | 17.0654 s         | 0.01707 s | 0.01575 s |
| 10000      | ~23660.4 s (~6h34m) | 1.56241 s | 1.57841 s |

#### Algorithme 2 (linÃ©aire optimisÃ©)
| Taille NÃ—N | Produit matriciel | Addition | Hadamard |
|------------|------------------:|---------:|----------:|
| 1000       | 0.01133 s         | 0.01121 s | 0.01113 s |
| 10000      | 1.19419 s         | 1.14798 s | 1.15504 s |

---

### GPU (NVIDIA GTX 1660 Super â€” TU116, 1408 cÅ“urs CUDA, 6 Go VRAM)

#### Algorithme 3 (CUDA optimisÃ©, cuBLAS, algorithme de tiling pour le produit de Hadamard)
| Taille NÃ—N | Produit matriciel | Addition | Hadamard |
|------------|------------------:|---------:|----------:|
| 1000       | 0.00489 s         | 0.00182 s | 0.00023 s |
| 10000      | 0.64972 s         | 0.01178 s | 0.00953 s |

---

## âœ… Conclusion
- Lâ€™algorithme naÃ¯f est **impraticable** pour de grandes tailles (ex. produit 10000Ã—10000 prend **6h34m**).  
- Lâ€™optimisation CPU rÃ©duit drastiquement le temps (de **6h34m â†’ ~1.2s**) grÃ¢ce Ã  l'accession linÃ©aires des donnÃ©es.  
- Le GPU est encore plus performant pour les gros calculs, atteignant **0.65s** pour une matrice 10000Ã—10000, avec la librairie optimisÃ© cuBLAS.  

â³ **GPU >> CPU optimisÃ© >> CPU naÃ¯f**  
---

## ğŸ”® AmÃ©liorations possibles
- ImplÃ©menter le **tiling** et le **caching** pour les kernels CUDA, utile pour les trÃ¨s grosses matrices (Impossible Ã  stocker en mÃ©moire).  
- ImplÃ©menter une interface visuelle ergonomique comme **QT**.
- Ã‰tendre aux matrices non carrÃ©es.

## ğŸ‘‰ N'hÃ©sitez pas Ã  me faire des retours si vous pensez que cela puisse m'aider/Ãªtre intÃ©ressant ! 
